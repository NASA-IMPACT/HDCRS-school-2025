{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb85522-53a4-43fb-95bc-b37d953662c4",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook provides a practical guide to fine-tuning the Prithvi Earth Observation (EO) v2.0 model, specifically for the task of identifying burn scars within Harmonized Landsat Sentinel (HLS) imagery. The primary learning objectives are:\n",
    "\n",
    "- To demonstrate the use of Terratorch for fine-tuning the Prithvi EO v2.0 (300M parameter model) to detect burn scars.\n",
    "- To illustrate the integration and use of Hugging Face datasets with Prithvi EO models during the fine-tuning process.\n",
    "- To develop an understanding of how various training parameters affect model performance and the utilization of hardware resources.\n",
    "\n",
    "AWS Sagemaker Training jobs will be used for finetuning the models. \n",
    "\n",
    "\n",
    "# Setup\n",
    "Go to \"Kernel\"\n",
    "Select \"prithvi_eo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae36e6-0ca6-47eb-88a0-9922b0f9db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import yaml\n",
    "import rasterio\n",
    "import sagemaker\n",
    "\n",
    "from datetime import time\n",
    "from glob import glob\n",
    "\n",
    "from huggingface_hub import hf_hub_download, snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c584a",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "\n",
    "For this hands-on session, Burn Scars example will be used for fine-tuning. All of the data and pre-trained models are available in Huggingface. Huggingface packages and git will be utilized to download, and prepare datasets and pretrained models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c4f1ad",
   "metadata": {},
   "source": [
    "### Download HLS Burn Scars dataset from Huggingface: https://huggingface.co/datasets/ibm-nasa-geospatial/hls_burn_scars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c4e10-15cd-4f52-8dfe-ec04074efe43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/hls_burn_scars\"\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"ibm-nasa-geospatial/hls_burn_scars\",\n",
    "    allow_patterns=\"hls_burn_scars.tar.gz\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=DATA_PATH,\n",
    ")\n",
    "!tar -xvzf ../data/hls_burn_scars/hls_burn_scars.tar.gz -C ../data/hls_burn_scars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f74d4f-8084-4c19-8be3-cb4cebbae855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sagemaker session with files uploaded to s3 bucket\n",
    "\n",
    "BUCKET_NAME = <BUCKET_NAME>\n",
    "\n",
    "# Prepare sagemaker session with files uploaded to s3 bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "train_images = sagemaker_session.upload_data(path=f'{DATA_PATH}/training', bucket=BUCKET_NAME, key_prefix='datasets/training')\n",
    "val_images = sagemaker_session.upload_data(path=f'{DATA_PATH}/validation', bucket=BUCKET_NAME, key_prefix='datasets/validation')\n",
    "test_images = sagemaker_session.upload_data(path=f'{DATA_PATH}/validation', bucket=BUCKET_NAME, key_prefix='datasets/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef75557",
   "metadata": {},
   "source": [
    "## Prepare config and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377435dd-4f07-4e0d-b4d8-33bed20d0116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../configs/prithvi_v2_eo_300_tl_unet_burnscars.yaml') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c8ecf-cc92-44aa-b32d-fca260a87688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_band_statistics(image_directory, image_pattern, bands=[0, 1, 2, 3, 4, 5]):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of each band in a folder of GeoTIFF files.\n",
    "\n",
    "    Args:\n",
    "        image_directory (str): Directory where the source GeoTIFF files are stored that are passed to model for training.\n",
    "        image_pattern (str): Pattern of the GeoTIFF file names that globs files for computing stats.\n",
    "        bands (list, optional): List of bands to calculate statistics for. Defaults to [0, 1, 2, 3, 4, 5].\n",
    "\n",
    "    Raises:\n",
    "        Exception: If no images are found in the given directory.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two lists containing the means and standard deviations of each band.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store the means and standard deviations\n",
    "    all_means = []\n",
    "    all_stds = []\n",
    "\n",
    "    # Use glob to get a list of all .tif images in the directory\n",
    "    all_images = glob(f\"{image_directory}/{image_pattern}\")\n",
    "\n",
    "    # Make sure there are images to process\n",
    "    if not all_images:\n",
    "        raise Exception(\"No images found\")\n",
    "\n",
    "    # Get the number of bands\n",
    "    num_bands = len(bands)\n",
    "\n",
    "    # Initialize arrays to hold sums and sum of squares for each band\n",
    "    band_sums = np.zeros(num_bands)\n",
    "    band_sq_sums = np.zeros(num_bands)\n",
    "    pixel_counts = np.zeros(num_bands)\n",
    "\n",
    "    # Iterate over each image\n",
    "    for image_file in all_images:\n",
    "        with rasterio.open(image_file) as src:\n",
    "            # For each band, calculate the sum, square sum, and pixel count\n",
    "            for band in bands:\n",
    "                data = src.read(band + 1)  # rasterio band index starts from 1\n",
    "                band_sums[band] += np.nansum(data)\n",
    "                band_sq_sums[band] += np.nansum(data**2)\n",
    "                pixel_counts[band] += np.count_nonzero(~np.isnan(data))\n",
    "\n",
    "    # Calculate means and standard deviations for each band\n",
    "    for i in bands:\n",
    "        mean = band_sums[i] / pixel_counts[i]\n",
    "        std = np.sqrt((band_sq_sums[i] / pixel_counts[i]) - (mean**2))\n",
    "        all_means.append(mean)\n",
    "        all_stds.append(std)\n",
    "\n",
    "    return all_means, all_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a856a9",
   "metadata": {},
   "source": [
    "# Configuration for training\n",
    "\n",
    "-   `identifier`: This variable will be used as a prefix for all artifacts related to fine-tuning and deployments. Please update it with an appropriate identifier.\n",
    "-   `usecase`: This variable refers to the use cases the Prithvi model will be fine-tuned for, e.g., `burn_scars`, `flood_detection`, etc. For this hands-on session, we will be using `burn_scars`. If you have your own data, please update accordingly.\n",
    "-   `data_path`: Data path is where the data locally resides. This will be used to find the files for fine-tuning. These files will then be used to calculate statistics like `mean` and `standard deviation`. These files will also be uploaded to an S3 bucket for the training job to use.\n",
    "-   `batch_size`: This is the number of data samples processed by the model in one iteration during training. We are using `4` by default. Depending on the availability of GPUs and resources, this can be increased.\n",
    "-   `num_workers`: This is the number of worker processes used for data loading during training. We are using `2` by default. This can be adjusted based on CPU and I/O capabilities.\n",
    "-   `num_classes`: This variable represents the number of classes in the fine-tuning job. For `burn_scars`, we have two classes: `burn_scar` and `no_burn_scar`. Update it according to the data you are using for training.\n",
    "-   `prithvi_backbone`: This variable represents the Prithvi Earth Observation Foundation Model (EO FM) pre-trained using HLS data. There are several variations:\n",
    "    -   `prithvi_eo_v1_100`: This is an older version of the Prithvi EO FM. It will not be used in this hands-on session.\n",
    "    -   `prithvi_eo_v2_300`: This version of the Prithvi EO FM has approximately 300 million parameters (typically around 24 Transformer encoder layers). It can be selected for faster training and a lower memory footprint.\n",
    "    -   `prithvi_eo_v2_300_tl`: This version also has ~300 million parameters (typically around 24 Transformer encoder layers) and is pre-trained with **T**emporal and **L**ocation embeddings. It is ideal for fine-tuning use cases where spatial and temporal information is important and a smaller footprint is desired. For example, crop classification using imagery from multiple time steps.\n",
    "    -   `prithvi_eo_v2_600`: This is a larger version of the Prithvi EO FM with approximately 600 million parameters (typically 32 Transformer encoder layers). It can be selected for use cases requiring high precision, accuracy, or recall. Note: the memory footprint of this model is significantly larger than the 300M versions. Ensure sufficient resources are available.\n",
    "    -   `prithvi_eo_v2_600_tl`: This version also has ~600 million parameters (typically 32 Transformer encoder layers) and includes **T**emporal and **L**ocation embeddings. It is best suited for high-performance fine-tuning on use cases where precise spatial and temporal information is crucial, such as detailed change detection or multi-temporal crop type mapping. The resource considerations are similar to the `prithvi_eo_v2_600` model.\n",
    "-   `base_path`: This variable specifies the base directory for training operations, including the path for input data, configuration files, and the location for storing model artifacts post-training. For SageMaker training jobs, `/opt/ml/data` is commonly used. If using a different environment, please update accordingly.\n",
    "-   `max_epochs`: This variable limits the number of `epochs` (full passes through the training dataset) a fine-tuning job runs for. A higher number of epochs equates to longer training time and may lead to better-performing models, but this needs to be validated on a case-by-case basis to avoid overfitting.\n",
    "-   `indices`: For most of our fine-tuning jobs, a `decoder` is added on top of the selected Prithvi backbone. This variable specifies which Transformer blocks (by their index) from the Prithvi backbone will provide their output feature embeddings to this decoder. Commonly, features from blocks at or around 1/4, 1/2, 3/4, and the final depth of the backbone are used to capture multi-scale information. The selection of these indices impacts the architecture and parameter count of the decoder, not the Prithvi backbone itself.\n",
    "-   `means`: This is the mean of the pixel values across each channel of the training dataset. The mean values, along with standard deviations, will be used for zero-center normalization of input values.\n",
    "-   `stds`: This is the standard deviation of the pixel values across each channel of the training dataset. The standard deviation values, along with means, will be used for zero-center normalization of input values.\n",
    "-   `model_path`: This variable specifies where the model artifacts will be stored after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to modify\n",
    "identifier = <identifier>\n",
    "usecase = <usecase>\n",
    "#local data path\n",
    "data_path = '../data/hls_burn_scars/'\n",
    "\n",
    "batch_size = 4\n",
    "num_workers = 2\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "\"\"\"\n",
    "Model backbone can be either:\n",
    "  - prithvi_eo_v1_100\n",
    "  - prithvi_eo_v2_300\n",
    "  - prithvi_eo_v2_300_tl\n",
    "  - prithvi_eo_v2_600\n",
    "  - prithvi_eo_v2_600_tl\n",
    "\"\"\"\n",
    "prithvi_backbone = 'prithvi_eo_v2_300' \n",
    "\n",
    "base_path = '/opt/ml/data'\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "config['data']['init_args']['batch_size'] = batch_size\n",
    "config['data']['init_args']['num_workers'] = num_workers\n",
    "\n",
    "config['data']['init_args']['num_classes'] = num_classes\n",
    "\n",
    "\n",
    "config['model']['init_args']['model_args']['backbone'] = prithvi_backbone\n",
    "\n",
    "\n",
    "indices = [5, 11, 17, 23]\n",
    "if 'prithvi_eo_v2_100' in prithvi_backbone:\n",
    "    indices = [2, 5, 8, 11]  # indices for prithvi_eo_v1_100\n",
    "elif 'prithvi_eo_v2_300' in prithvi_backbone: \n",
    "    indices = [5, 11, 17, 23]  # indices for prithvi_eo_v2_300\n",
    "elif 'prithvi_eo_v2_600' in prithvi_backbone:\n",
    "    indices = [7, 15, 23, 31]  # indices for prithvi_eo_v2_600\n",
    "\n",
    "config['model']['init_args']['model_args']['necks'][0]['indices'] = indices\n",
    "\n",
    "means, stds = calculate_band_statistics(data_path, 'training/*_merged.tif')\n",
    "\n",
    "model_path = f\"{base_path}/{usecase}/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b163ac-8f44-4ab2-8341-c9a9d2ac5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and standard deviation calculated from the training dataset for all 6 bands,\n",
    "# for zero center normalization.\n",
    "config['data']['init_args']['means'] = [float(val) for val in means]\n",
    "config['data']['init_args']['stds'] = [float(val) for val in stds]\n",
    "\n",
    "# Total number of epochs the training will run for. Since we are short on time,\n",
    "# we will just be running it for 1 epoch. This can be updated to any positive integer.\n",
    "config['trainer']['max_epochs'] = max_epochs\n",
    "\n",
    "config['data']['init_args']['test_data_root'] = f\"{base_path}/test\"\n",
    "config['data']['init_args']['val_data_root'] = f\"{base_path}/validation\"\n",
    "config['data']['init_args']['train_data_root'] = f\"{base_path}/training\"\n",
    "\n",
    "config['trainer']['default_root_dir'] = f\"{base_path}/{usecase}\"\n",
    "\n",
    "config['trainer']['callbacks'][2]['init_args'][\"dirpath\"] = model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5139e3c-158a-455f-9369-7110359ccb2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename configuration file name to user specific filename\n",
    "import os\n",
    "\n",
    "config_filename = f\"{identifier}-burn_scars_Prithvi-EO.yaml\"\n",
    "config_filepath = f\"../configs/{config_filename}\"\n",
    "with open(config_filepath, 'w') as config_file:\n",
    "    yaml.dump(config, config_file, default_flow_style=False)\n",
    "\n",
    "# Upload config files to s3 bucket\n",
    "configs = sagemaker_session.upload_data(path=config_filepath, bucket=BUCKET_NAME, key_prefix='data/configs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d6b5d-d58d-4b90-a952-6179c255280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables for training using sagemaker\n",
    "\n",
    "name = f'{identifier}-sagemaker'\n",
    "role = get_execution_role()\n",
    "input_s3_uri = f\"s3://{BUCKET_NAME}/data\"\n",
    "model_name = f\"{identifier}-workshop.ckpt\",\n",
    "\n",
    "environment_variables = {\n",
    "    'CONFIG_FILE': f\"{base_path}/configs/{config_filename}\",\n",
    "    'MODEL_DIR': model_path,\n",
    "    'MODEL_NAME': model_name,\n",
    "    'S3_URL': input_s3_uri,\n",
    "    'ROLE_ARN': role,\n",
    "    'ROLE_NAME': role.split('/')[-1],\n",
    "    'EVENT_TYPE': usecase,\n",
    "    'VERSION': 'v1'\n",
    "}\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_container_url = f'{account_id}.dkr.ecr.us-west-2.amazonaws.com/eo_training:latest'\n",
    "sagemaker_role = 'SageMaker-ExecutionRole-20240206T151814'\n",
    "\n",
    "instance_type = 'ml.p3.2xlarge'\n",
    "\n",
    "instance_count = 1\n",
    "memory_volume = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b5c5a-9510-4d3f-8b11-dab8fdd8ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish an estimator (model) using sagemaker and the configurations from the previous cell.\n",
    "estimator = Estimator(image_uri=ecr_container_url,\n",
    "                      role=get_execution_role(),\n",
    "                      base_job_name=name,\n",
    "                      instance_count=1,\n",
    "                      environment=environment_variables,\n",
    "                      instance_type=instance_type)\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbb9e6-1b3e-4596-91f9-e3be9f734e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save important values in a file for reuse.\n",
    "export_values = {\n",
    "    'identifier': identifier,\n",
    "    'model_name': model_name,\n",
    "    'config_filename': config_filename,\n",
    "    'bucket_name': BUCKET_NAME\n",
    "}\n",
    "\n",
    "with open('../variables.yaml', 'w') as variable_export:\n",
    "    yaml.dump(export_values, variable_export, default_flow_style=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8987afb44532b2110e1a5e1b229dd281f8440b44477d285826a54acdd52d8797"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

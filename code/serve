#!/usr/bin/env python3.11

# This file implements the scoring service shell. You don't necessarily need to modify it for various
# algorithms. It starts nginx and gunicorn with the correct configurations and then simply waits until
# gunicorn exits.
#
# The flask server is specified to be the app object in wsgi.py
#
# We set the following parameters:
#
# Parameter                Environment Variable              Default Value
# ---------                --------------------              -------------
# number of workers        MODEL_SERVER_WORKERS              the number of CPU cores
# timeout                  MODEL_SERVER_TIMEOUT              60 seconds

import os
import sys
import time # For timestamps

# --- VERY FIRST EXECUTABLE LINES ---
print(f"{time.time()}: SERVE_SCRIPT_DEBUG: Starting execution of /opt/program/serve.", file=sys.stderr, flush=True)
print(f"{time.time()}: SERVE_SCRIPT_DEBUG: Python version: {sys.version}", file=sys.stderr, flush=True)
print(f"{time.time()}: SERVE_SCRIPT_DEBUG: Current User ID: {os.geteuid()}", file=sys.stderr, flush=True)
print(f"{time.time()}: SERVE_SCRIPT_DEBUG: Working Directory: {os.getcwd()}", file=sys.stderr, flush=True)
env_vars_for_debug = {k: v for k, v in os.environ.items() if 'SAGEMAKER_' in k or 'AWS_' in k or 'MODEL_SERVER_' in k}
print(f"{time.time()}: SERVE_SCRIPT_DEBUG: Key Environment Variables: {env_vars_for_debug}", file=sys.stderr, flush=True)
# Check critical file existence
critical_files = ["/opt/program/nginx.conf", "/opt/program/wsgi.py"] # Add any other crucial files
for f_path in critical_files:
    print(f"{time.time()}: SERVE_SCRIPT_DEBUG: Checking file {f_path} - Exists: {os.path.exists(f_path)}", file=sys.stderr, flush=True)
print(f"{time.time()}: SERVE_SCRIPT_DEBUG: Initial checks complete. Proceeding with imports and function definitions.", file=sys.stderr, flush=True)
# --- END OF VERY EARLY PRINTS ---

import multiprocessing
import os
import signal
import subprocess
import sys

cpu_count = multiprocessing.cpu_count()

model_server_timeout = os.environ.get('MODEL_SERVER_TIMEOUT', 60)
model_server_workers = int(os.environ.get('MODEL_SERVER_WORKERS', cpu_count))

def sigterm_handler(nginx_pid, gunicorn_pid):
    try:
        os.kill(nginx_pid, signal.SIGQUIT)
    except OSError:
        pass
    try:
        os.kill(gunicorn_pid, signal.SIGTERM)
    except OSError:
        pass

    sys.exit(0)

def start_server():
    print('Starting the inference server with {} workers.'.format(model_server_workers))


    # link the log streams to stdout/err so they will be logged to the container logs
    subprocess.check_call(['ln', '-sf', '/dev/stdout', '/var/log/nginx/access.log'])
    subprocess.check_call(['ln', '-sf', '/dev/stderr', '/var/log/nginx/error.log'])

    nginx = subprocess.Popen(['nginx', '-c', '/opt/program/nginx.conf'])
    gunicorn = subprocess.Popen(['gunicorn',
                                 '--timeout', str(model_server_timeout),
                                 '-b', 'unix:/tmp/gunicorn.sock',
                                 '-w', '1',
                                 '--worker-class', 'uvicorn.workers.UvicornWorker',
                                 'predictor:app'])

    signal.signal(signal.SIGTERM, lambda a, b: sigterm_handler(nginx.pid, gunicorn.pid))

    # If either subprocess exits, so do we.
    pids = set([nginx.pid, gunicorn.pid])
    while True:
        pid, _ = os.wait()
        if pid in pids:
            break

    sigterm_handler(nginx.pid, gunicorn.pid)
    print('Inference server exiting')

# The main routine just invokes the start function.

if __name__ == '__main__':
    start_server()
